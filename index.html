<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Casting Multiple Shadows</title>
    <meta charset="utf-8" />
    <meta name="author" content="Stuart Lee, Monash University" />
    <link href="libs/font-awesome-5.3.1/css/fontawesome-all.min.css" rel="stylesheet" />
    <link rel="stylesheet" href="saltheme.css" type="text/css" />
    <link rel="stylesheet" href="extra.css" type="text/css" />
    <link rel="stylesheet" href="animate.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: left, middle, inverse, title-slide

# Casting Multiple Shadows
## High-Dimensional Interactive Data Visualisation with Tours and Embeddings
### <span style="font-size: 90%;">Stuart Lee, Monash University</span>
### <span style="font-size: 90%;">Pre-submission Seminar<br><br> Tuesday 10th March, 2020 </span> <br><br>

---


layout: true
&lt;div class="my-footer"&gt;&lt;span&gt;bit.ly/39vj1mF ‚Ä¢ @sa-lee&lt;/span&gt;&lt;/div&gt; 






---

# Overview

.large[
* Big Picture
* Orientation: t-distributed stochastic neighbour embedding
* Orientation: tours
* `liminal` package and usage examples
]


---

# Big picture: dimensionality reduction

.large[
Let `\(X\)` be an `\(n \times p\)` real data matrix, where `\(n\)` is the number of observations in `\(p\)` dimensions. 

The goal of dimensionality reduction (DR) is to find a low dimensional data representation `\(Y\)`, such that `\(Y\)` is an `\(n \times d\)` matrix where `\(d \ll p\)`.   
]
---
class: middle

.large[
_Aspiration: the DR procedure  will remove **noise** in the data while revealing **hidden patterns and structure**._
]

---
# DR approaches

.large[_Linear_: `\(Y\)` is a linear transformation of the input `\(X\)`, i.e. principal components analysis (PCA).

_Non-linear_: `\(Y\)` is generated via a pre-processed form of the input `\(X\)` such as the `\(k\)`-nearest neighbours graph or a kernel transformation. 
]


---
class: middle, center

# How are DR methods used in the wild?

---

# Cluster identification...



&lt;img src="img/cluster-p-1.png" width="80%" height="80%" style="display: block; margin: auto;" /&gt;

---
# ... and verification


&lt;img src="img/cluster-p2-1.png" width="80%" height="80%" style="display: block; margin: auto;" /&gt;

---
class: middle

.pull-left[
&lt;img src="img/masocko.png" width="100%" height="100%" style="display: block; margin: auto;" /&gt;
.small[Retinal cell map from Macosko et al., 2015]
]

.pull-right[
&lt;img src="img/umap-digits.png" width="100%" height="100%" style="display: block; margin: auto;" /&gt;
.small[Screenshot of Tensorflow Embedding Projector]
]

---

# Dimension synthesis... 


&lt;img src="img/unnamed-chunk-3-1.png" width="80%" height="80%" style="display: block; margin: auto;" /&gt;

---
# ... revealing continuous gradients

&lt;img src="img/gp2-1.png" width="80%" style="display: block; margin: auto;" /&gt;

---
class: middle

.pull-left[
&lt;img src="img/trajectory.png" width="100%" height="100%" style="display: block; margin: auto;" /&gt;
.small[Single cell trajectory and branches from _(Setty et. al, 2016)_]
]

.pull-right[
&lt;img src="img/gradients-ecology.jpg" width="100%" height="100%" style="display: block; margin: auto;" /&gt;
.small[Horseshoes in ecology _(Podani and Mikl√≥s, 2002)_]
]

---
class: inverse, middle

.large[
**Assumption**: 
the DR form is _"faithful"_ to the source high-dimensional data
] 

---

# Orientation with t-SNE

.large[**t-distributed stochastic neighbour embedding**

- extremely popular in bioinformatics and machine learning
- human interpretation can be difficult due to distortions
- highly flexible parameterisations
]

---

.large[
Our high dimensional dataset oriented row wise

`$$X = [\mathbf{x_1}, ..., \mathbf{x_n}] \subset \mathbb{R}^p$$` 
and our target lower dimensional embedding  
`$$Y =  [\mathbf{y_1}, ..., \mathbf{y_n}] \subset \mathbb{R}^d$$`

_for visualisation  `\(d \in \{1,2,3\}\)`_.
]
---

# How does it work?

.large[_Key idea:_ transform pairwise `\(\mathbf{x_i}\)` and `\(\mathbf{x_j}\)` 
distances to joint probabilities using a Gaussian kernel

`\(p_{i|j} = \frac{\exp(-\lVert \mathbf{x_i - x_j} \rVert ^ 2 / 2\sigma_i^2)}{\sum_{k \ne i}\exp(-\lVert \mathbf{x_j - x_k} \rVert ^ 2 / 2\sigma_i^2)}\)` and `\(p_{ij} = \frac{p_{i|j} + p_{j|i}}{2}\)`
]

---

# How does it work?

.large[The variance `\(\sigma_{i}^2\)` of the Gaussian is chosen based on user supplied value of perplexity:

`\(\text{perplexity}_i = \exp(-\log(2) \sum_{i \ne j}p_{j|i}\log_2(p_{j|i}))\)`


_Perplexity controls the number of nearest neighbours._ 
]

---

# How does it work?

.large[
_Key idea:_ transform pairwise distances `\(\mathbf{y_i}\)` and `\(\mathbf{y_j}\)` to joint probabilities using a Cauchy kernel:

`$$q_{ij} = \frac{w_{ij}}{Z}$$` 

where `\(w_{ij} = \frac{1}{ 1 + \lVert \mathbf{y_i - y_j} \rVert ^ 2}\)` and `\(Z = \sum_{k \ne l} w_{kl}.\)`
]

---

# How does it work?

.large[
Obtain `\(Y\)` so that Kullback-Leibler divergence between
the probability distributions `\(\mathcal{P}\)` and `\(\mathcal{Q}\)` is minimised:

`$$\mathcal{L} = \sum_{i \ne j} p_{ij} \log \frac{p_{ij}}{q_{ij}}$$`
]

---

# How does it work?

.large[
The loss function can be recast in terms of .red[attractive] and .blue[repulsive] forces:

`$$\mathcal{L} = \color{red}{-\sum_{i \ne j} p_{ij}\log w_{ij}} + \color{blue}{\log\sum_{i \ne j} w_{ij}}$$`
]


---

# Important Parameters

.large[
- perplexity 
- early exaggeration 
- step size (learning rate)
- number of iterations
- initialisation of `\(Y\)` (default is random)
]

---
class: inverse, middle, center

# That's a lot! Let's look at pictures!

---

# Continuous gradients revisited
 
where `\(n = 500\)` and `\(p = 10\)`

.center[
&lt;img src="img/gradients-revisited-1.png" width="80%" style="display: block; margin: auto;" /&gt;
]




---

# Now with more t-SNE

.center[
&lt;img src="img/gradients-revisted-tsne-1.png" width="80%" style="display: block; margin: auto;" /&gt;
]
---

# t-SNE gives a lot of flexibility

.large[
- there's a lot of parameters to tweak
- emphasises locality, distance between clusters of points can be misleading
- size of clusters can be misleading 
- may require a few different runs to capture topology of data
- if there are clusters it will find them 
]

---
class: middle, inverse, center


# tSNE is state of the art, but how can we help analysts understand it?


---

# Orientation with tours

.large[

- a technique from statistical graphics
- has been successfully applied to problems in particle physics and model interpretation
- can be used to visualise `\(d \gt 3\)` using `\(d = 1\)` or `\(d=2\)` views

]

---


# Description

.large[
Recall our `\(n \times p\)` data matrix `\(X\)`

A tour is sequence of `\(p \times d\)` orthonormal projection matrices (bases) `\(A_{t \in \mathbb{N}}\)`, where `\(d\)` is typically `\(1\)` or `\(2\)`.

A tour allows us to explore the set of all `\(d\)`-dimensional subspaces via the projection of `\(X\)` onto `\(A\)`. 
]

---

# How does it work?

.large[
We visualise the sequence of low dimensional projections:

`$$Y_{t} = XA_{t}$$`

as animated scatter or density plots. 
]

---

.large[**Grand Tour:** generate a set of random orthnormal bases, interpolate between them.]

&lt;img src="img/bases-generation.png" width="50%" style="display: block; margin: auto;" /&gt;

(From _Buja, Cook, Asimov and Hurley, 2004_)
---

class: middle

.large[The tour is enhanced by **interactivity**:

- play/pause the current projection
- zooming to find 'interesting' points
- highlighting sets of points
- linking multiple views
]

---
class: inverse, middle, center

# A brief software sojourn

---

# `liminal` an R package for interactive tours

.large[
- extends the `tourr` package but uses a modern R API
- leverage client-side visualisation and interaction via `vegawidget`
- treats the basis generation/interpolation steps as a reactive stream  
]


---
class: middle, center
# Demo #1, the secret word is...

---

# Tours as reactive streams

.large[
- don't need to realise the entire sequence
- instead generate new bases according to a fixed frame rate
- allows user interactions to play/pause on the current view
]
---
class: middle, center

# Demo #2, continuous gradients revisited (again)

---

# Thesis driven development

.large[
- `liminal` began life as [`sneezy`](https://github.com/sa-lee/sneezy)
- __desire__ to have interactivity built in from the start
- __building__ on top of `vegawidget`
- prototype `\(\longleftrightarrow\)` edge-case `\(\longleftrightarrow\)` re-factor 

]

---

class: inverse, middle, center

# Casting multiple shadows

---

class: middle, center

&lt;img src="img/multiple-shadows.jpg" width="50%" style="display: block; margin: auto;" /&gt;

---

# Why settle for 'just' one visualisation?

.medium[

&lt;img src="img/ensemble-example.jpeg" width="50%" style="display: block; margin: auto;" /&gt;
Ensemble Graphics provide new perspectives and connections 
_(Unwin, 2018)_
]

---

# `liminal` an R package for ensembling tours and embeddings

.large[
- **concatenated views:** see local and global structures
- **user interactions:** verify cluster shapes and locations
- **quality checks:** interrogate an embedding with reference
to the underlying data
]


---

# Case study: High-dimensional trees, `\(p=100\)`, `\(n=3000\)`

.center[
&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="img/tree.png" alt="Example from Kevin Moon" width="50%" /&gt;
&lt;p class="caption"&gt;Example from Kevin Moon&lt;/p&gt;
&lt;/div&gt;
]


---
class: inverse, middle, center

# Demo 3: linked highlighting shows how default t-SNE breaks topology

---
class: inverse, middle, center

# Demo 4: simple linked brushing identifies distortions


---
class: inverse, middle

.large[
**Assumption**: 
the DR form is _"faithful"_ to the source high-dimensional data
] 


---

class: middle, center

.huge[Or: how do you know if an embedding is 'good'?]


---
class: middle, center

.huge[
**Answer**: It depends.
]

---

# A non-exhaustive list of things you could look at

.medium[
- **distance preservation**: what is the relationship between pairwise distances in `\(X\)` and pairwise distances in `\(Y\)`?
- **neighbourhood preservation**:  do points in `\(Y\)` have the same nearest neighbours as those in `\(X\)`? And vice-versa?
- **rank preservation**: replace distances with ranks 
]

---
class: middle, center


.huge[Can these be investigated visually?]

---

# Spatial linking


.large[

**distortion**: points that are far away in one view, will show neighbours that are close together in the opposing view.

**diffusion**: points that are close in one view, will show neighbours that are far apart in the opposing view. 

]


---
# Spatial linking

.large[
**Key idea:** Look up nearest neighbours graph
from points that lie in a brushing region.

Highlight the corresponding neighbours using colour or transparency in the linked view. 
]


---

# Spatial linking

.medium[
- The `\(k\)` nearest neighbours graph can be pre-computed quickly, for either `\(X\)`, `\(Y\)` or both.
- Instead of using the neighbour indices, we could use the neighbour distances instead.
- Composition of multiple brushes could be used to show where there are matches/mismatches between nearest neighbour graphs. 
]


&lt;!-- # Case study: QuickDraw --&gt;

&lt;!-- --- --&gt;

&lt;!-- # Description --&gt;

&lt;!-- --- --&gt;

&lt;!-- # When does a cat look like a dog? --&gt;

&lt;!-- --- --&gt;

---

# Thesis driven development: part 2

.large[
- adding interactions increases code complexity
- __latency:__  round-trips between R and Javascript 
- __discoverability:__ specifying UI elements at the code level or within the app?
- __displays:__ appropriate visual encodings for large _n_

]

---

# Next steps

.medium[
- Implementation and testing of spatial brushes
- Cleaner user controls and interface
- Scaling up for larger datasets
- Exploration of other non-linear embedding techniques
- Getting the package on CRAN
]


---
class: inverse, middle, center

# How does this fit in?

---
class: center, middle

&lt;img src="img/data-science.png" width="80%" style="display: block; margin: auto;" /&gt;

_(Wickham and Wickham, 2017)_

---
class: center, middle

&lt;img src="img/data-science-wrangle.png" width="80%" style="display: block; margin: auto;" /&gt;

---
class: center, middle

&lt;img src="img/data-science-wrangle.png" width="80%" style="display: block; margin: auto;" /&gt;

.large[
üë©üèΩ
üî¨üß¨üß¨üë®üèª
üî¨
]
---

&lt;img src="img/plyranges-paper.png" width="80%" style="display: block; margin: auto;" /&gt;

&lt;img src="img/plyranges.png" width="30%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="img/f1000.png" width="80%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="img/superintronic-paper.png" width="80%" style="display: block; margin: auto;" /&gt;

&lt;img src="img/superintronic.png" width="30%" style="display: block; margin: auto;" /&gt;
---
class: middle, center 

&lt;img src="img/data-science-wrangle.png" width="80%" style="display: block; margin: auto;" /&gt;
.large[
üë©üèΩ
üî¨üß¨üß¨üë®üèª
üî¨
]

---
class: middle, center

&lt;img src="img/data-science-explore.png" width="80%" style="display: block; margin: auto;" /&gt;

---
# Take homes

.large[

* DR oriented workflows are complemented by the tour
* Composing multiple views provides more insight 
* User interactions allow us to explore and check t-SNE views


]

---

# Thanks

.large.pull-left[
- Di Cook
- Matt Ritchie
- Paul Harrison
]

.large.pull-right[
- David Frazier
- Charity Law
- Ursula Laa
- Nick Tierney
- Earo Wang
]



---

# Colophon

.medium[
- Slides made using [xaringan](https://github.com/yihui/xaringan) using [Nick Tierney's template](https://github.com/njtierney/njt-talks)
- Extended with [xaringanthemer](https://github.com/gadenbuie/xaringanthemer)
- Colours taken + modified from [Maureen Stone's Tableau10 Palettes](https://research.tableau.com/user/maureen-stone)
- Header font is **Montserrat**
- Body text font is **Open Sans**
- Code font is **Fira Mono**
]

---

# Learning more

.large[
<i class="fas  fa-box-open "></i> [liminal](https://github.com/sa-lee/liminal)

<i class="fas  fa-link "></i> [talk link](https://bit.ly/39vj1mF)
]


---

.vhuge[
**End.**
]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
