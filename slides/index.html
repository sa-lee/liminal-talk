<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Casting Multiple Shadows</title>
    <meta charset="utf-8" />
    <meta name="author" content="Stuart Lee, Monash University" />
    <link href="libs/font-awesome-5.3.1/css/fontawesome-all.min.css" rel="stylesheet" />
    <link rel="stylesheet" href="saltheme.css" type="text/css" />
    <link rel="stylesheet" href="extra.css" type="text/css" />
    <link rel="stylesheet" href="animate.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: left, middle, inverse, title-slide

# Casting Multiple Shadows
## high-dimensional interactive data visualisation with tours and embeddings
### <span style="font-size: 90%;">Stuart Lee, Monash University</span>
### <span style="font-size: 90%;">Final Review<br><br> Tuesday 10th March, 2020 </span> <br><br>

---


layout: true
&lt;div class="my-footer"&gt;&lt;span&gt;bit.ly/LINK â€¢ @sa-lee&lt;/span&gt;&lt;/div&gt; 







---
class: inverse, middle, center

# The story so far...

---
class: center, middle

&lt;img src="img/data-science-explore.png" width="80%" style="display: block; margin: auto;" /&gt;

---
class: center, middle

&lt;img src="img/data-science-explore-human.png" width="80%" style="display: block; margin: auto;" /&gt;

---
class: center, middle

&lt;img src="img/data-science-explore-me.png" width="80%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="img/plyranges-paper.png" width="80%" style="display: block; margin: auto;" /&gt;

&lt;img src="img/plyranges.png" width="30%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="img/f1000.png" width="80%" style="display: block; margin: auto;" /&gt;

---

&lt;img src="img/superintronic-paper.png" width="80%" style="display: block; margin: auto;" /&gt;

&lt;img src="img/superintronic.png" width="30%" style="display: block; margin: auto;" /&gt;
---
class: inverse, middle, center 

&lt;img src="img/data-science-explore-human.png" width="80%" style="display: block; margin: auto;" /&gt;

---
class: middle, center

&lt;img src="img/data-science-explore-human-now.png" width="80%" style="display: block; margin: auto;" /&gt;


---
class: middle, center

# high-dimensional interactive data visualisation with tours and embedding

---

# Overview

* Big Picture
* Orientation: t-distributed stochastic neighbor embedding
* Orientation: tours
* Why interactive graphics are a must
* Our approach `liminal` and implementation details
* Case studies


---

.pull-left[
&lt;img src="img/masocko.png" width="100%" height="100%" style="display: block; margin: auto;" /&gt;
.small[Retinal cell map from Macosko et al., 2015]
]

.pull-right[
&lt;img src="img/umap-digits.png" width="100%" height="100%" style="display: block; margin: auto;" /&gt;
.small[Screenshot of Tensorflow Embedding Projector]
]



---

# Big picture: dimensionality reduction

.large[
Let `\(X\)` be an `\(n \times p\)` real data matrix, where `\(n\)` is the number of observations in `\(p\)` dimensions. 

The goal of dimensionality reduction (DR) is to find a low dimensional data representation `\(Y\)`, such that `\(Y\)` is an `\(n \times d\)` matrix where `\(d \ll p\)`.   
]
---
class: middle

.large[
_Aspiration: the DR procedure  will remove **noise** in the data while revealing **hidden patterns and structure**._
]

---
# DR approaches

.large[_Linear_: `\(Y\)` is a linear transformation of the input `\(X\)`, i.e. principal components analysis (PCA).

_Non-linear_: `\(Y\)` is generated via a pre-processed form of the input `\(X\)` such as the `\(k\)`-nearest neighbours graph or a kernel transformation. 
]


---
class: middle, center

# How are DR methods used in the wild?

---

# Cluster idenfication...



&lt;img src="img/unnamed-chunk-4-1.png" width="80%" height="80%" style="display: block; margin: auto;" /&gt;

---
# ... and verification


&lt;img src="img/unnamed-chunk-5-1.png" width="80%" height="80%" style="display: block; margin: auto;" /&gt;

---

# Dimension synthesis... 


&lt;img src="img/unnamed-chunk-7-1.png" width="80%" height="80%" style="display: block; margin: auto;" /&gt;

---
# ... revealing continous gradients

&lt;img src="img/unnamed-chunk-8-1.png" width="80%" style="display: block; margin: auto;" /&gt;



---
class: inverse, middle

.large[
**Assumption**: 
the DR form is _"faithful"_ to the high-dimensional data it was obtained 
] 

---

# Orientation with t-SNE

.large[**t-distributed stochastic neighbour embedding**

- extremely popular in bioinformatics and machine learning
- human interpretation can be difficult due to distortions
- highly flexible parameterisations
]

---

# Description

Our high dimensional dataset `\(X = [\mathbf{x_1}, ..., \mathbf{x_n}] \subset \mathbb{R}^p\)` and our target lower dimensional embedding  `\(Y =  [\mathbf{y_1}, ..., \mathbf{y_n}] \subset \mathbb{R}^d\)`

_for visualisation generally `\(d =  2\)` or `\(d = 3\)`
---

# How does it work?

.large[Key idea: model pairwise high-dimensional distances as joint probabilities using a Gaussian kernel

`\(p_{i|j} = \frac{\exp(-\lVert \mathbf{x_i - x_j} \rVert ^ 2 / 2\sigma_i^2)}{\sum_{k \ne i}\exp(-\lVert \mathbf{x_j - x_k} \rVert ^ 2 / 2\sigma_i^2)}\)` and `\(p_{ij} = \frac{p_{i|j} + p_{j|i}}{2}\)`
]

---

# How does it work?

.large[The variance `\(\sigma_{i}^2\)` is chosen based on user supplied
value of perplexity:

`\(\text{perplexity}_i = \exp(-\log(2) \sum_{i \ne j}p_{j|i}\log_2(p_{j|i}))\)`

_The larger the value of perplexity, the larger the variance.
Perpelxity controls the number of nearest neighbors._ 
]

---

# How does it work?

.large[
Key idea: model pairwise distances in the embedding space `\(Y\)` as joint probabilities using a Cauchy kernel:

`$$q_{ij} = \frac{w_{ij}}{Z}$$` 

where `\(w_{ij} = \frac{1}{ 1 + \lVert \mathbf{y_i - y_j} \rVert ^ 2}\)` and `\(Z = \sum_{k \ne l} w_{kl}.\)`
]

---

# How does it work?

.large[
Obtain `\(Y\)` that minimises the Kullback-Leibler divergence between
the probability distrubtions:

`$$\sum_{i \ne j} p_{ij} \log \frac{p_{ij}}{q_{ij}}$$`
]

---

# How does it work?

.large[
The loss function can be recast in terms of .red[attractive] and .blue[repulsive] forces:

`$$\color{red}{-\sum_{i \ne j} p_{ij}\log w_{ij}} + \color{blue}{\log\sum_{i \ne j} w_{ij}}$$`
]


---

# Important Parameters

.large[
- perplexity 
- early exaggeration (adds a multiplier to the attractive force)
- step size (learning rate)
- number of iterations
- initialisation of `\(Y\)`
]

---
class: inverse, middle, center

# That's a lot! Let's look at pictures!

---

# Continuous gradients 

&lt;img src="img/unnamed-chunk-9-1.png" width="80%" style="display: block; margin: auto;" /&gt;

---

# Orientation with tours

---


# Description

---

# How does it work?

---



# Why do we need interactivity?

---

# Tours as streams

---

# How does this work?

---

# Hidden messages


```r
library(liminal)
data(pollen, package = "animation")
limn_tour(pollen, cols = dplyr::everything())
```

---

# Hidden messages



---

# Our approach: you can have it all

---

# Ensemble graphics

---

# Interactions

---

# Linked Brushing and Highlighting

---

# How do they work?

---

# Case study: High-dimensional trees

---

# Description

---

# Linked highlighting shows how t-SNE breaks topology

---

# Reparmeterising partially fixes the problem

---

# Linked Brushing identifies distortions

---

# Case study: QuickDraw

---

# Description

---

# When does a cat look like a dog?

---

# Limitations

---

# Spatially resolved brushes

---

# How do they work?

---

# Future Directions

.large[
- More features
- More features
- More features
]

---

# Take homes

---


# Acknowledgements

.large.pull-left[
- Di Cook
- Matt Ritchie
- Paul Harrison
]

.large.pull-right[
- Ursula Laa
- Nick Tierney
]

---

# Colophon

.large[
- Slides made using [xaringan](https://github.com/yihui/xaringan)
- Extended with [xaringanthemer](https://github.com/gadenbuie/xaringanthemer)
- Colours taken + modified from [Kiki's Delivery Service](https://github.com/ewenme/ghibli)
- Header font is **Montserrat**
- Body text font is **Open Sans**
- Code font is **Fira Mono**
]

---

# Learning more

.large[
<i class="fas  fa-box-open "></i> [liminal](https://github.com/sa-lee/liminal)

<i class="fas  fa-link "></i> [talk link]()
]


---

.vhuge[
**End.**
]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
